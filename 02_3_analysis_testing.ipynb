{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm\n",
    "from settings import settings\n",
    "from sklearn.utils import resample\n",
    "from scipy.stats import multivariate_normal\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from sklearn.linear_model import LinearRegression, Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "regional_mkt_ret = pd.read_parquet(data_path / \"regional_mkt_ret.parquet\")\n",
    "cluster_labels = pd.read_parquet(data_path / \"cluster_labels.parquet\")\n",
    "char_info = pd.read_excel(\n",
    "    \"Factor Details.xlsx\", sheet_name=\"details\", usecols=\"A:N\"\n",
    ").dropna(subset=[\"abr_jkp\"]).rename(\n",
    "    columns={\n",
    "        \"abr_jkp\": \"characteristic\",\n",
    "        \"in-sample period\": \"date_range\",\n",
    "        \"group\": \"hxz_group\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path / \"eb_est.pkl\", \"rb\") as f:\n",
    "    eb_est = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR(False Discover Rate) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr_sim(t_low, a_vec, a_cov, n_sim=10000, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    t_all = a_vec / np.sqrt(np.diag(a_cov))\n",
    "\n",
    "    t_steps = np.sort(t_all[t_all > t_low])\n",
    "    t_steps = t_steps[:-1]\n",
    "\n",
    "    sims = multivariate_normal.rvs(mean=a_vec, cov=a_cov, size=n_sim)\n",
    "    results = []\n",
    "    for t in tqdm(t_steps):\n",
    "        # Significant alphas under t-cutoff\n",
    "        sig = t_all >= t\n",
    "        sims_fdr = np.mean(\n",
    "            np.sign(sims[:, sig]) != np.sign(np.tile(a_vec[sig].values, (n_sim, 1))),\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        fdr = np.mean(sims_fdr)\n",
    "        fwr = np.mean(sims_fdr > 0)\n",
    "\n",
    "        results.append({\"t_cutoff\": t, \"n_sig\": np.sum(sig), \"fdr\": fdr, \"fwr\": fwr})\n",
    "\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 141/141 [00:00<00:00, 9591.10it/s]\n"
     ]
    }
   ],
   "source": [
    "model_fdr = fdr_sim(\n",
    "    t_low=0,\n",
    "    a_vec=eb_est[\"us\"][\"factor_mean\"].copy(),\n",
    "    a_cov=eb_est[\"us\"][\"factor_cov\"].copy(),\n",
    "    n_sim=10000,\n",
    "    # n_sim=10,\n",
    "    seed=settings[\"seed\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pvalues(group):\n",
    "    group[\"n\"] = len(group)\n",
    "    group[\"p_bonf\"] = multipletests(group[\"p_ols\"], method=\"bonferroni\")[1]\n",
    "    group[\"p_holm\"] = multipletests(group[\"p_ols\"], method=\"holm\")[1]\n",
    "    group[\"p_bh\"] = multipletests(group[\"p_ols\"], method=\"fdr_bh\")[1]\n",
    "    group[\"p_by\"] = multipletests(group[\"p_ols\"], method=\"fdr_by\")[1]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiple_testing(eb_all, eb_world=None):\n",
    "    combined_df = (\n",
    "        pd.concat([eb_all[\"factors\"], eb_world[\"factors\"]])\n",
    "        if eb_world\n",
    "        else eb_all[\"factors\"]\n",
    "    )\n",
    "    combined_df = combined_df.set_index(\"region\") \n",
    "\n",
    "    # Calculate t_ols and p_ols\n",
    "    combined_df[\"t_ols\"] = combined_df[\"ols_est\"] / combined_df[\"ols_se\"]\n",
    "    combined_df[\"p_ols\"] = 2 * norm.sf(np.abs(combined_df[\"t_ols\"]))\n",
    "\n",
    "    combined_df = (\n",
    "        combined_df.groupby(\"region\", group_keys=False).apply(adjust_pvalues).reset_index()\n",
    "    )\n",
    "    # Select relevant columns and reshape the DataFrame\n",
    "    combined_df = combined_df.loc[\n",
    "        :,\n",
    "        [\n",
    "            \"n\",\n",
    "            \"region\",\n",
    "            \"char_reg\",\n",
    "            \"ols_est\",\n",
    "            \"t_ols\",\n",
    "            \"ols_se\",\n",
    "            \"p_ols\",\n",
    "            \"p_bonf\",\n",
    "            \"p_holm\",\n",
    "            \"p_bh\",\n",
    "            \"p_by\",\n",
    "        ],\n",
    "    ]\n",
    "    combined_df = combined_df.melt(\n",
    "        id_vars=[\"n\", \"region\", \"char_reg\", \"ols_est\", \"t_ols\", \"ols_se\"],\n",
    "        value_vars=[\"p_ols\", \"p_bonf\", \"p_holm\", \"p_bh\", \"p_by\"],\n",
    "        var_name=\"method\",\n",
    "        value_name=\"p\",\n",
    "    )\n",
    "    # Add method and mt_adj columns\n",
    "    combined_df['method'] = combined_df['method'].str.replace('p_', '').map({\n",
    "        'ols': 'OLS',\n",
    "        'bonf': 'Bonferroni',\n",
    "        'holm': 'Holm',\n",
    "        'bh': 'BH',\n",
    "        'by': 'BY'\n",
    "    })\n",
    "    combined_df['mt_adj'] = combined_df['method'].map({\n",
    "        'OLS': 'None',\n",
    "        'BH': 'FDR',\n",
    "        'BY': 'FDR',\n",
    "        'Bonferroni': 'FWR',\n",
    "        'Holm': 'FWR'\n",
    "    })\n",
    "    return combined_df.copy()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = multiple_testing(\n",
    "    eb_all = eb_est[\"all\"].copy(),\n",
    "    eb_world = eb_est[\"world\"].copy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>region</th>\n",
       "      <th>char_reg</th>\n",
       "      <th>ols_est</th>\n",
       "      <th>t_ols</th>\n",
       "      <th>ols_se</th>\n",
       "      <th>method</th>\n",
       "      <th>p</th>\n",
       "      <th>mt_adj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>153</td>\n",
       "      <td>developed</td>\n",
       "      <td>age__developed</td>\n",
       "      <td>0.408229</td>\n",
       "      <td>2.916042</td>\n",
       "      <td>0.139994</td>\n",
       "      <td>OLS</td>\n",
       "      <td>3.545028e-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>153</td>\n",
       "      <td>developed</td>\n",
       "      <td>aliq_at__developed</td>\n",
       "      <td>0.907554</td>\n",
       "      <td>6.399943</td>\n",
       "      <td>0.141807</td>\n",
       "      <td>OLS</td>\n",
       "      <td>1.554353e-10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153</td>\n",
       "      <td>developed</td>\n",
       "      <td>aliq_mat__developed</td>\n",
       "      <td>0.029489</td>\n",
       "      <td>0.206205</td>\n",
       "      <td>0.143006</td>\n",
       "      <td>OLS</td>\n",
       "      <td>8.366305e-01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>153</td>\n",
       "      <td>developed</td>\n",
       "      <td>ami_126d__developed</td>\n",
       "      <td>0.185177</td>\n",
       "      <td>1.210297</td>\n",
       "      <td>0.153002</td>\n",
       "      <td>OLS</td>\n",
       "      <td>2.261650e-01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>developed</td>\n",
       "      <td>at_be__developed</td>\n",
       "      <td>0.120585</td>\n",
       "      <td>0.850471</td>\n",
       "      <td>0.141786</td>\n",
       "      <td>OLS</td>\n",
       "      <td>3.950632e-01</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3055</th>\n",
       "      <td>153</td>\n",
       "      <td>world</td>\n",
       "      <td>turnover_var_126d__world</td>\n",
       "      <td>-0.139822</td>\n",
       "      <td>-1.629332</td>\n",
       "      <td>0.085816</td>\n",
       "      <td>BY</td>\n",
       "      <td>6.978802e-01</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3056</th>\n",
       "      <td>153</td>\n",
       "      <td>world</td>\n",
       "      <td>z_score__world</td>\n",
       "      <td>0.014332</td>\n",
       "      <td>0.131466</td>\n",
       "      <td>0.109016</td>\n",
       "      <td>BY</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3057</th>\n",
       "      <td>153</td>\n",
       "      <td>world</td>\n",
       "      <td>zero_trades_126d__world</td>\n",
       "      <td>0.427679</td>\n",
       "      <td>4.974097</td>\n",
       "      <td>0.085981</td>\n",
       "      <td>BY</td>\n",
       "      <td>1.042127e-05</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3058</th>\n",
       "      <td>153</td>\n",
       "      <td>world</td>\n",
       "      <td>zero_trades_21d__world</td>\n",
       "      <td>0.196193</td>\n",
       "      <td>2.285974</td>\n",
       "      <td>0.085825</td>\n",
       "      <td>BY</td>\n",
       "      <td>1.619147e-01</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3059</th>\n",
       "      <td>153</td>\n",
       "      <td>world</td>\n",
       "      <td>zero_trades_252d__world</td>\n",
       "      <td>0.507746</td>\n",
       "      <td>5.896329</td>\n",
       "      <td>0.086112</td>\n",
       "      <td>BY</td>\n",
       "      <td>7.782315e-08</td>\n",
       "      <td>FDR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3060 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        n     region                  char_reg   ols_est     t_ols    ols_se  \\\n",
       "0     153  developed            age__developed  0.408229  2.916042  0.139994   \n",
       "1     153  developed        aliq_at__developed  0.907554  6.399943  0.141807   \n",
       "2     153  developed       aliq_mat__developed  0.029489  0.206205  0.143006   \n",
       "3     153  developed       ami_126d__developed  0.185177  1.210297  0.153002   \n",
       "4     153  developed          at_be__developed  0.120585  0.850471  0.141786   \n",
       "...   ...        ...                       ...       ...       ...       ...   \n",
       "3055  153      world  turnover_var_126d__world -0.139822 -1.629332  0.085816   \n",
       "3056  153      world            z_score__world  0.014332  0.131466  0.109016   \n",
       "3057  153      world   zero_trades_126d__world  0.427679  4.974097  0.085981   \n",
       "3058  153      world    zero_trades_21d__world  0.196193  2.285974  0.085825   \n",
       "3059  153      world   zero_trades_252d__world  0.507746  5.896329  0.086112   \n",
       "\n",
       "     method             p mt_adj  \n",
       "0       OLS  3.545028e-03   None  \n",
       "1       OLS  1.554353e-10   None  \n",
       "2       OLS  8.366305e-01   None  \n",
       "3       OLS  2.261650e-01   None  \n",
       "4       OLS  3.950632e-01   None  \n",
       "...     ...           ...    ...  \n",
       "3055     BY  6.978802e-01    FDR  \n",
       "3056     BY  1.000000e+00    FDR  \n",
       "3057     BY  1.042127e-05    FDR  \n",
       "3058     BY  1.619147e-01    FDR  \n",
       "3059     BY  7.782315e-08    FDR  \n",
       "\n",
       "[3060 rows x 9 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tangency Portfolios "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_tpf(data, n_boots=100, shorting=True, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    if shorting:\n",
    "        def boot_func(df):\n",
    "            # Normalize each column by its standard deviation\n",
    "            df_normalized = df.apply(lambda x: x / np.std(x), axis=0)\n",
    "            \n",
    "            # Perform linear regression without intercept\n",
    "            model = LinearRegression(fit_intercept=False)\n",
    "            model.fit(df_normalized, np.ones(df_normalized.shape[0]))\n",
    "            \n",
    "            # Extract the coefficients and compute weights\n",
    "            weights = model.coef_ / np.sum(model.coef_)\n",
    "            result = pd.DataFrame({\n",
    "                'term': df.columns,\n",
    "                'weight': weights\n",
    "            })\n",
    "            return result\n",
    "        \n",
    "    # Shorting not allowed (non-negative weights)\n",
    "    else:\n",
    "        def boot_func(df):\n",
    "            import warnings \n",
    "            warnings.filterwarnings(\"ignore\")\n",
    "            # Normalize each column by its standard deviation\n",
    "            df_normalized = df.apply(lambda x: x / np.std(x), axis=0)\n",
    "            \n",
    "            # Use Lasso regression with lambda=0 and non-negative constraints\n",
    "            model = Lasso(alpha=0, fit_intercept=False, positive=True)\n",
    "            model.fit(df_normalized, np.ones(df_normalized.shape[0]))\n",
    "            \n",
    "            # Extract the coefficients and compute weights\n",
    "            weights = model.coef_ / np.sum(model.coef_)\n",
    "            result = pd.DataFrame({\n",
    "                'term': df.columns,\n",
    "                'weight': weights\n",
    "            })\n",
    "            return result\n",
    "        \n",
    "    results = []\n",
    "    for i in tqdm(range(n_boots)):\n",
    "        # Resample the data with replacement\n",
    "        bootstrapped_data = resample(data, replace=True, random_state=seed + i)\n",
    "        coef = boot_func(bootstrapped_data)\n",
    "        coef = coef.set_index(\"term\").T.reset_index(drop=True)\n",
    "        results.append(coef)\n",
    "    result = pd.concat(results) \n",
    "    result.index = pd.RangeIndex(n_boots, name=\"bootstrap_iteration\") \n",
    "    return result.reset_index().copy()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpf_cluster(data, mkt_region, orig_sig, min_date, n_boots, shorting, seed):\n",
    "    print(f\"Run: {mkt_region}\")\n",
    "\n",
    "    if orig_sig:\n",
    "        orig_sig_values = [1]\n",
    "    else:\n",
    "        orig_sig_values = [1, 0]\n",
    "    \n",
    "    # Filter market return based on region\n",
    "    market_ret = regional_mkt_ret[regional_mkt_ret['region'] == mkt_region].reset_index()\n",
    "    cluster_pf = (\n",
    "        data\n",
    "        .merge(cluster_labels, on=\"characteristic\", how=\"left\")\n",
    "        .merge(char_info[['characteristic', 'significance']].rename(columns={\"significance\": \"orig_sig\"}), on=\"characteristic\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    # Cluster 안에 있는 요인들의 수익률 평균\n",
    "    cluster_pf = (\n",
    "        cluster_pf[cluster_pf[\"orig_sig\"].isin(orig_sig_values)]\n",
    "        .groupby(['hcl_label', 'eom'], as_index=False)\n",
    "        .agg(ret=('ret', 'mean'))\n",
    "    )\n",
    "\n",
    "    tpf_data = (\n",
    "        cluster_pf[cluster_pf[\"eom\"] >= min_date]\n",
    "        .pivot(index='eom', columns='hcl_label', values='ret')\n",
    "        .reset_index()\n",
    "        .merge(market_ret[['eom', 'market']], on='eom', how='left')\n",
    "        .rename(columns={'market': 'Market'})\n",
    "    )\n",
    "\n",
    "    tpf_bootstrap = bootstrap_tpf(tpf_data.drop(columns=['eom']), n_boots=n_boots, shorting=shorting, seed=seed) \n",
    "    tpf_bootstrap['market_region'] = mkt_region\n",
    "    return tpf_bootstrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tangency Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_tpf_save = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_tpf_save:\n",
    "    tpf_world = tpf_cluster(eb_est['world']['input']['long'], mkt_region='world', orig_sig=True, min_date=settings['tpf']['start']['world'],\n",
    "                            n_boots=settings['tpf']['bs_samples'], shorting=settings['tpf']['shorting'], seed=settings['seed'])\n",
    "\n",
    "    tpf_us = tpf_cluster(eb_est['us']['input']['long'], mkt_region='us', orig_sig=True, min_date=settings['tpf']['start']['us'],\n",
    "                        n_boots=settings['tpf']['bs_samples'], shorting=settings['tpf']['shorting'], seed=settings['seed'])\n",
    "\n",
    "    tpf_dev = tpf_cluster(eb_est['developed']['input']['long'], mkt_region='developed', orig_sig=True, min_date=settings['tpf']['start']['developed'],\n",
    "                        n_boots=settings['tpf']['bs_samples'], shorting=settings['tpf']['shorting'], seed=settings['seed'])\n",
    "\n",
    "    tpf_emer = tpf_cluster(eb_est['emerging']['input']['long'], mkt_region='emerging', orig_sig=True, min_date=settings['tpf']['start']['emerging'],\n",
    "                        n_boots=settings['tpf']['bs_samples'], shorting=settings['tpf']['shorting'], seed=settings['seed'])\n",
    "\n",
    "    # Size Groups\n",
    "    tpf_size = pd.concat([\n",
    "        tpf_cluster(eb_est[f'us_{x}']['input']['long'], mkt_region='us', orig_sig=True, min_date=settings['tpf']['start']['size_grps'],\n",
    "                    n_boots=settings['tpf']['bs_samples'], shorting=settings['tpf']['shorting'], seed=settings['seed']).assign(size_grp=x)\n",
    "        for x in [\"mega\", \"large\", \"small\", \"micro\", \"nano\"]\n",
    "    ])\n",
    "\n",
    "    tpf_all = pd.concat([\n",
    "        tpf_world, \n",
    "        tpf_us, \n",
    "        tpf_dev, \n",
    "        tpf_emer, \n",
    "        tpf_size, \n",
    "    ])\n",
    "    tpf_all.to_parquet(data_path / \"tpf_all.parquet\")\n",
    "else: \n",
    "    tpf_all = pd.read_parquet(data_path / \"tpf_all.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>term</th>\n",
       "      <th>bootstrap_iteration</th>\n",
       "      <th>Accruals</th>\n",
       "      <th>Debt Issuance</th>\n",
       "      <th>Investment</th>\n",
       "      <th>Low Leverage</th>\n",
       "      <th>Low Risk</th>\n",
       "      <th>Momentum</th>\n",
       "      <th>Profit Growth</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Quality</th>\n",
       "      <th>Seasonality</th>\n",
       "      <th>Short-Term Reversal</th>\n",
       "      <th>Size</th>\n",
       "      <th>Value</th>\n",
       "      <th>Market</th>\n",
       "      <th>market_region</th>\n",
       "      <th>size_grp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.203477</td>\n",
       "      <td>0.018953</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014192</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005828</td>\n",
       "      <td>0.041738</td>\n",
       "      <td>0.103680</td>\n",
       "      <td>0.074951</td>\n",
       "      <td>0.093575</td>\n",
       "      <td>0.043726</td>\n",
       "      <td>0.169193</td>\n",
       "      <td>0.013058</td>\n",
       "      <td>0.217630</td>\n",
       "      <td>world</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.199051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065819</td>\n",
       "      <td>0.040643</td>\n",
       "      <td>0.034408</td>\n",
       "      <td>0.042118</td>\n",
       "      <td>0.055944</td>\n",
       "      <td>0.088506</td>\n",
       "      <td>0.154788</td>\n",
       "      <td>0.020580</td>\n",
       "      <td>0.052583</td>\n",
       "      <td>0.031170</td>\n",
       "      <td>0.214390</td>\n",
       "      <td>world</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.200437</td>\n",
       "      <td>0.024690</td>\n",
       "      <td>0.043566</td>\n",
       "      <td>0.017079</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>0.028756</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.099490</td>\n",
       "      <td>0.131541</td>\n",
       "      <td>0.013290</td>\n",
       "      <td>0.052610</td>\n",
       "      <td>0.115965</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.204511</td>\n",
       "      <td>world</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.175737</td>\n",
       "      <td>0.007459</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.013111</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018854</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085401</td>\n",
       "      <td>0.122826</td>\n",
       "      <td>0.086774</td>\n",
       "      <td>0.054496</td>\n",
       "      <td>0.195674</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229943</td>\n",
       "      <td>world</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.223260</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061096</td>\n",
       "      <td>0.114575</td>\n",
       "      <td>0.133800</td>\n",
       "      <td>0.063055</td>\n",
       "      <td>0.062306</td>\n",
       "      <td>0.001710</td>\n",
       "      <td>0.089337</td>\n",
       "      <td>0.018840</td>\n",
       "      <td>0.214559</td>\n",
       "      <td>world</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.086764</td>\n",
       "      <td>0.048995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.147381</td>\n",
       "      <td>0.196917</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251051</td>\n",
       "      <td>0.106386</td>\n",
       "      <td>0.085911</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022725</td>\n",
       "      <td>0.053870</td>\n",
       "      <td>us</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9996</td>\n",
       "      <td>0.062650</td>\n",
       "      <td>0.049223</td>\n",
       "      <td>0.034240</td>\n",
       "      <td>0.137314</td>\n",
       "      <td>0.171394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019935</td>\n",
       "      <td>0.232337</td>\n",
       "      <td>0.079086</td>\n",
       "      <td>0.065684</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008109</td>\n",
       "      <td>0.068070</td>\n",
       "      <td>0.071959</td>\n",
       "      <td>us</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9997</td>\n",
       "      <td>0.059563</td>\n",
       "      <td>0.013788</td>\n",
       "      <td>0.006275</td>\n",
       "      <td>0.092014</td>\n",
       "      <td>0.109767</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072037</td>\n",
       "      <td>0.272587</td>\n",
       "      <td>0.038309</td>\n",
       "      <td>0.163228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111850</td>\n",
       "      <td>0.060581</td>\n",
       "      <td>us</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.022660</td>\n",
       "      <td>0.073454</td>\n",
       "      <td>0.036773</td>\n",
       "      <td>0.158111</td>\n",
       "      <td>0.230811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.165315</td>\n",
       "      <td>0.116690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110878</td>\n",
       "      <td>0.085309</td>\n",
       "      <td>us</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.062804</td>\n",
       "      <td>0.007549</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.118413</td>\n",
       "      <td>0.192706</td>\n",
       "      <td>0.010663</td>\n",
       "      <td>0.004421</td>\n",
       "      <td>0.226759</td>\n",
       "      <td>0.061872</td>\n",
       "      <td>0.132780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.122653</td>\n",
       "      <td>0.059381</td>\n",
       "      <td>us</td>\n",
       "      <td>nano</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "term  bootstrap_iteration  Accruals  Debt Issuance  Investment  Low Leverage  \\\n",
       "0                       0  0.203477       0.018953    0.000000      0.014192   \n",
       "1                       1  0.199051       0.000000    0.000000      0.065819   \n",
       "2                       2  0.200437       0.024690    0.043566      0.017079   \n",
       "3                       3  0.175737       0.007459    0.009726      0.013111   \n",
       "4                       4  0.223260       0.000000    0.017462      0.000000   \n",
       "...                   ...       ...            ...         ...           ...   \n",
       "9995                 9995  0.086764       0.048995    0.000000      0.147381   \n",
       "9996                 9996  0.062650       0.049223    0.034240      0.137314   \n",
       "9997                 9997  0.059563       0.013788    0.006275      0.092014   \n",
       "9998                 9998  0.022660       0.073454    0.036773      0.158111   \n",
       "9999                 9999  0.062804       0.007549    0.000000      0.118413   \n",
       "\n",
       "term  Low Risk  Momentum  Profit Growth  Profitability   Quality  Seasonality  \\\n",
       "0     0.000000  0.005828       0.041738       0.103680  0.074951     0.093575   \n",
       "1     0.040643  0.034408       0.042118       0.055944  0.088506     0.154788   \n",
       "2     0.011148  0.028756       0.056915       0.099490  0.131541     0.013290   \n",
       "3     0.000000  0.018854       0.000000       0.085401  0.122826     0.086774   \n",
       "4     0.000000  0.061096       0.114575       0.133800  0.063055     0.062306   \n",
       "...        ...       ...            ...            ...       ...          ...   \n",
       "9995  0.196917  0.000000       0.000000       0.251051  0.106386     0.085911   \n",
       "9996  0.171394  0.000000       0.019935       0.232337  0.079086     0.065684   \n",
       "9997  0.109767  0.000000       0.072037       0.272587  0.038309     0.163228   \n",
       "9998  0.230811  0.000000       0.000000       0.165315  0.116690     0.000000   \n",
       "9999  0.192706  0.010663       0.004421       0.226759  0.061872     0.132780   \n",
       "\n",
       "term  Short-Term Reversal      Size     Value    Market market_region size_grp  \n",
       "0                0.043726  0.169193  0.013058  0.217630         world     None  \n",
       "1                0.020580  0.052583  0.031170  0.214390         world     None  \n",
       "2                0.052610  0.115965  0.000000  0.204511         world     None  \n",
       "3                0.054496  0.195674  0.000000  0.229943         world     None  \n",
       "4                0.001710  0.089337  0.018840  0.214559         world     None  \n",
       "...                   ...       ...       ...       ...           ...      ...  \n",
       "9995             0.000000  0.000000  0.022725  0.053870            us     nano  \n",
       "9996             0.000000  0.008109  0.068070  0.071959            us     nano  \n",
       "9997             0.000000  0.000000  0.111850  0.060581            us     nano  \n",
       "9998             0.000000  0.000000  0.110878  0.085309            us     nano  \n",
       "9999             0.000000  0.000000  0.122653  0.059381            us     nano  \n",
       "\n",
       "[90000 rows x 17 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpf_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finance",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
